{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc45b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T21:02:06.265088Z",
     "iopub.status.busy": "2026-01-31T21:02:06.264852Z",
     "iopub.status.idle": "2026-01-31T21:02:10.794055Z",
     "shell.execute_reply": "2026-01-31T21:02:10.793234Z"
    },
    "papermill": {
     "duration": 4.5337,
     "end_time": "2026-01-31T21:02:10.795528",
     "exception": false,
     "start_time": "2026-01-31T21:02:06.261828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'autovision-cityscapes'...\r\n",
      "remote: Enumerating objects: 22, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (22/22), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\r\n",
      "remote: Total 22 (delta 4), reused 20 (delta 2), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (22/22), 9.25 MiB | 29.04 MiB/s, done.\r\n",
      "Resolving deltas: 100% (4/4), done.\r\n",
      "âœ… Fixed imports in utils.py\n",
      "ðŸš€ Fine-Tuning Environment Ready on cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 1. Clone the AutoVision Repo\n",
    "REPO_URL = \"https://github.com/Kaankocc/autovision-cityscapes.git\"\n",
    "REPO_NAME = \"autovision-cityscapes\"\n",
    "if not os.path.exists(REPO_NAME):\n",
    "    !git clone {REPO_URL}\n",
    "\n",
    "# 2. Add to Python Path\n",
    "PROJECT_PATH = os.path.abspath(REPO_NAME)\n",
    "SRC_PATH = os.path.join(PROJECT_PATH, \"src\")\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "\n",
    "# 3. Fix Imports (The \"src.\" remover)\n",
    "for filename in ['utils.py', 'dataset.py', 'model.py']:\n",
    "    path = os.path.join(SRC_PATH, filename)\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.read()\n",
    "    if 'from src.' in content:\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(content.replace('from src.', 'from '))\n",
    "        print(f\"âœ… Fixed imports in {filename}\")\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ðŸš€ Fine-Tuning Environment Ready on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59691627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T21:02:10.800994Z",
     "iopub.status.busy": "2026-01-31T21:02:10.800632Z",
     "iopub.status.idle": "2026-01-31T21:04:53.826632Z",
     "shell.execute_reply": "2026-01-31T21:04:53.825647Z"
    },
    "papermill": {
     "duration": 163.030588,
     "end_time": "2026-01-31T21:04:53.828420",
     "exception": false,
     "start_time": "2026-01-31T21:02:10.797832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Baking masks from /kaggle/input/cityscapes-image-pairs/cityscapes_data/cityscapes_data...\n",
      "ðŸ”¥ Baking 2975 masks for 'train' split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2975/2975 [02:15<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Baking 500 masks for 'val' split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:22<00:00, 22.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Masks baked at /kaggle/working/processed_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import bake_masks\n",
    "import shutil\n",
    "\n",
    "# 1. Define Paths\n",
    "RAW_DATA = \"/kaggle/input/cityscapes-image-pairs/cityscapes_data/cityscapes_data\"\n",
    "PROC_DATA = \"/kaggle/working/processed_masks\"\n",
    "\n",
    "# 2. Bake Masks (if not already done)\n",
    "if not os.path.exists(PROC_DATA):\n",
    "    print(f\"ðŸ”¥ Baking masks from {RAW_DATA}...\")\n",
    "    bake_masks(RAW_DATA, PROC_DATA)\n",
    "    print(f\"âœ… Masks baked at {PROC_DATA}\")\n",
    "else:\n",
    "    print(\"ðŸ“‚ Masks already exist. Skipping bake.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99813e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T21:04:53.920122Z",
     "iopub.status.busy": "2026-01-31T21:04:53.919348Z",
     "iopub.status.idle": "2026-01-31T21:04:55.425010Z",
     "shell.execute_reply": "2026-01-31T21:04:55.424040Z"
    },
    "papermill": {
     "duration": 1.553054,
     "end_time": "2026-01-31T21:04:55.426434",
     "exception": false,
     "start_time": "2026-01-31T21:04:53.873380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading weights from: /kaggle/input/cityscapes-512-best-pth/pytorch/default/1/cityscapes_512_best.pth\n",
      "ðŸ§  Foundation weights loaded successfully.\n",
      "ðŸ“Š Initializing DataLoaders with Safe Mode...\n",
      "âœ… Ready to Train: 2975 images | Batch Size: 4 | Workers: 2\n"
     ]
    }
   ],
   "source": [
    "from model import UNet\n",
    "from dataset import CityscapesKaggleDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 4        \n",
    "NUM_WORKERS = 2       \n",
    "\n",
    "PRETRAINED_PATH = \"/kaggle/input/cityscapes-512-best-pth/pytorch/default/1/cityscapes_512_best.pth\" \n",
    "\n",
    "# 2. Initialize the Model\n",
    "model = UNet(n_channels=3, n_classes=7).to(device)\n",
    "\n",
    "# 3. Load the Weights\n",
    "if os.path.exists(PRETRAINED_PATH):\n",
    "    print(f\"ðŸ“‚ Loading weights from: {PRETRAINED_PATH}\")\n",
    "    model.load_state_dict(torch.load(PRETRAINED_PATH, map_location=device))\n",
    "    print(\"ðŸ§  Foundation weights loaded successfully.\")\n",
    "else:\n",
    "    print(f\"âŒ ERROR: Could not find file at {PRETRAINED_PATH}\")\n",
    "    print(\"Please check the path in the sidebar's 'Input' section.\")\n",
    "\n",
    "# 4. Prepare Data Loaders (With Safe Settings)\n",
    "print(\"ðŸ“Š Initializing DataLoaders with Safe Mode...\")\n",
    "train_ds = CityscapesKaggleDataset(root_dir=RAW_DATA, split='train', target_size=(512, 512))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS, \n",
    "    pin_memory=True         \n",
    ")\n",
    "\n",
    "print(f\"âœ… Ready to Train: {len(train_ds)} images | Batch Size: {BATCH_SIZE} | Workers: {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01a999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T21:04:55.515194Z",
     "iopub.status.busy": "2026-01-31T21:04:55.514573Z",
     "iopub.status.idle": "2026-01-31T21:04:55.520449Z",
     "shell.execute_reply": "2026-01-31T21:04:55.519753Z"
    },
    "papermill": {
     "duration": 0.050937,
     "end_time": "2026-01-31T21:04:55.521754",
     "exception": false,
     "start_time": "2026-01-31T21:04:55.470817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fine-Tuning Configuration Set:\n",
      "   - LR: 1e-5\n",
      "   - Human/Object Weight: 20.0\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. Class Weights for Fine-Tuning\n",
    "fine_tune_weights = torch.tensor([1.0, 1.0, 20.0, 2.0, 1.0, 20.0, 1.0]).to(device)\n",
    "\n",
    "# 2. Loss Function\n",
    "criterion = nn.CrossEntropyLoss(weight=fine_tune_weights)\n",
    "\n",
    "# 3. Optimizer with Low Learning Rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "print(\"âœ… Fine-Tuning Configuration Set:\")\n",
    "print(\"   - LR: 1e-5\")\n",
    "print(\"   - Human/Object Weight: 20.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31795f0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T21:04:55.607588Z",
     "iopub.status.busy": "2026-01-31T21:04:55.607344Z",
     "iopub.status.idle": "2026-01-31T22:15:04.989690Z",
     "shell.execute_reply": "2026-01-31T22:15:04.988852Z"
    },
    "papermill": {
     "duration": 4209.427069,
     "end_time": "2026-01-31T22:15:04.991136",
     "exception": false,
     "start_time": "2026-01-31T21:04:55.564067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¡ Starting Surgical Fine-Tuning for 5 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 744/744 [13:46<00:00,  1.11s/it, loss=0.1795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ Epoch 1 Done | Avg Loss: 0.1676\n",
      "ðŸ’¾ Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 744/744 [14:03<00:00,  1.13s/it, loss=0.1327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ Epoch 2 Done | Avg Loss: 0.1601\n",
      "ðŸ’¾ Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 744/744 [14:04<00:00,  1.14s/it, loss=0.1298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ Epoch 3 Done | Avg Loss: 0.1547\n",
      "ðŸ’¾ Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 744/744 [14:06<00:00,  1.14s/it, loss=0.1809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ Epoch 4 Done | Avg Loss: 0.1515\n",
      "ðŸ’¾ Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 744/744 [14:05<00:00,  1.14s/it, loss=0.1770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ Epoch 5 Done | Avg Loss: 0.1483\n",
      "ðŸ’¾ Model saved.\n",
      "\n",
      "âœ¨ Fine-Tuning Complete! Download 'cityscapes_finetuned.pth'.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 5\n",
    "best_loss = float('inf')\n",
    "\n",
    "print(f\"ðŸ“¡ Starting Surgical Fine-Tuning for {EPOCHS} epochs...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    for batch_idx, (images, masks) in pbar:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"ðŸ Epoch {epoch+1} Done | Avg Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save Checkpoint\n",
    "    torch.save(model.state_dict(), \"cityscapes_finetuned.pth\")\n",
    "    print(\"ðŸ’¾ Model saved.\")\n",
    "\n",
    "print(\"\\nâœ¨ Fine-Tuning Complete! Download 'cityscapes_finetuned.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a4d0c",
   "metadata": {
    "papermill": {
     "duration": 0.403743,
     "end_time": "2026-01-31T22:15:05.719587",
     "exception": false,
     "start_time": "2026-01-31T22:15:05.315844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 22655,
     "sourceId": 29047,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 574846,
     "modelInstanceId": 562227,
     "sourceId": 737317,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4384.062852,
   "end_time": "2026-01-31T22:15:07.963289",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-31T21:02:03.900437",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
